#I. DEFINITION
##PROJECT OVERVIEW
As post-secondary education becomes a common experience of the commonwealth, the budget of an education institution is often limited and funding is competitive. While working closely with many colleges and students, knowing the expectation of their investment is crucial for both. The project aims to figure out whether the allocation of expenditure can help predicting the performance of institution - which is defined by the number of awards, degree, and certificate granted - as it has been widely used to evaluate the performance of higher education institutes.
http://www.ncsl.org/research/education/performance-funding.aspx 
http://www.ed.gov/college-completion
This project is inspired by Udacity's capstone project guidance and uses dataset downloaded from Integrated Postsecondary Education Data System Delta Cost Project Database, which include the data from the academy year 1987-1988 to 2012-2013. The Delta Cost Project Database is derived from the Integrated Postsecondary Education Data System (IPEDS) surveys on finance, enrollment, staffing, completions, and student aid, and the data have been translated into analytical formats to allow for longitudinal analyses of trends in postsecondary education with a focus on revenues and expenditure.

##PROBLEM STATEMENT
The question asked with this project is whether expenditure can be used to predict completion number and if expenditure pattern can make a better predictor for the same target. Expenditure categories will be retrieved from the data set acquired through delta cost project database, The goal of this project is to identify if the expenditure pattern will be a better reference to predict high completion number than original data. 
Dealing with this problem, the target variable and the expenditure variables will be extracted from data set. 75% of randomly selected data set will be used as the training set, while the rest will be the testing set. The pattern of expenditure has to be found through expenditure variables in the training set. Performance of the model trained by original data will be compared with the performance of the model trained by expenditure pattern.

##METRICS
The models being evaluated will be regression models, and the estimate of error between predicted values and actual value would be the reference of performance. The options for regression models include Mean Absolute Error (MAE), Root of Mean Squared Error (RMSE), and R-squared score (R2).
Mean Absolute Error calculates the average of difference between predicted value and actual value. 
Root Mean Squared Error takes the root of the average squared distance between predicted value and actual value. Compare with MAE, RMSE weighs more on the error that is further away from mean. Both MAE and RMSE are negative oriented â€“ meaning the less the error the higher the accuracy is. When MAE equals to RMSE, it means every error are of the same magnitude.
R-squared calculates the variance of the true data set, and calculates the proportion that the predicted data can be accountable for. The residual of the variance indicates the variance caused by the difference between actual data and predicted data.  The much variance being explained by predicted data the higher the score is, which also indicates higher accuracy. R2, however, inflates when adding more predictors (variables) to the metric. The variance caused by predicted value hence increase even without model improvement. Adjusted R-squared score (Adj R2) is developed to counter the inflation and adding penalty for extra variables entering the metric. Adj R2 is always smaller or equals to R2 score.
When comparing MAE and RMSE, RMSE puts more weights on the larger error, and MAE behaves less sensitive to outliers. When comparing the model of original data and the model of transformed data set, it is likely the dimensionality changes. To avoid the inflation affects the R2 score should not be used as the metric of evaluation.  
